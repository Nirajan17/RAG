{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL USED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.6\n"
     ]
    }
   ],
   "source": [
    "import pydantic\n",
    "print(pydantic.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization of model and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/g978mxy128vghxxjgmlf7cfc0000gn/T/ipykernel_7925/2696963359.py:4: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  model = Ollama(model=MODEL)\n",
      "/var/folders/jm/g978mxy128vghxxjgmlf7cfc0000gn/T/ipykernel_7925/2696963359.py:5: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings = OllamaEmbeddings(model=MODEL)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "model = Ollama(model=MODEL)\n",
    "embeddings = OllamaEmbeddings(model=MODEL)\n",
    "# model.invoke(\"where are you prividing your response from\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document loaded and splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"./temp_paper-image-captioning.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/g978mxy128vghxxjgmlf7cfc0000gn/T/ipykernel_7925/1801323123.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages= True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating prompt for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the questions based on the context below. If you cannot answer the question given, just reply I don't know\n",
    "\n",
    "Context: {context}\n",
    "Chat History: {chat_history}\n",
    "Question: {question}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "# print(prompt.format(context=\"\", question=\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating a chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"context\":\"nepal\", \n",
    "        \"chat_history\":\"I like pokhara very much\",\n",
    "        \"question\":\"what is the city name\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pokhara is a city in Nepal! So, to answer your question, the city name is Pokhara.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "storing embeddings in vectorestores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nirajanpaudel17/anaconda3/envs/learn_crew/lib/python3.10/site-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(\n",
    "    pages, \n",
    "    embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating retreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "retreiver = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2024-04-30T10:30:12+05:30', 'author': 'Microsoft account', 'moddate': '2024-04-30T10:30:12+05:30', 'source': './temp_paper-image-captioning.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content=\"Nabaraj Subedi, Nirajan Paudel, Manish Chhetri, Sudarshan Acharya, Nabin Lamichhane  \\n \\nJournal of Soft Computing Paradigm, Month 2024, Volume 6, Issue 1  81 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nFigure 9. Sample Result 3 \\n \\n \\n \\n \\n \\n \\n \\nFigure 10. Sample Result 4 \\nThe transformer model correctly predicted the object, environment, relations and the \\nactions in the images with coherent sentences. \\n Conclusion \\nIn conclusion, our research work introduces a novel approach for generating detailed \\nNepali paragraphs to describe images, leveraging both visual and linguistic struct ures. The \\ntransformer's capacity to model long range dependencies on caption to effectively describe the\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2024-04-30T10:30:12+05:30', 'author': 'Microsoft account', 'moddate': '2024-04-30T10:30:12+05:30', 'source': './temp_paper-image-captioning.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='Nepali Image Captioning: Generating Coherent Paragraph-Length Descriptions Using Transformer \\nISSN: 2582-2640  76 \\n \\n \\n3.3.1 Caption Translation to Nepali \\nTranslating English captions into Nepali using Google Translator faces so me \\ndifficulties: \\n• Google Translate lacks the capability to consider context, resulting in the loss of \\nmeaning when translating captions. \\n• Frequently, Google Translate produces grammatically incorrect sentences. \\n• The reliability of Google Translator varies dep ending on the language \\ncombination being translated. \\n3.3.2 Manual Correction and Annotation \\nTo ensure accurate translations, we corrected errors in the Nepali captions generated by \\nGoogle Translate. Adhering to Nepali grammar rules, we invested significant  time, \\napproximately 3 to 4 months, to rectify the entire dataset. Ambiguous or incorrect captions \\nwere manually corrected or removed. \\n \\n                                            Figure 3. Caption Pre-processing'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2024-04-30T10:30:12+05:30', 'author': 'Microsoft account', 'moddate': '2024-04-30T10:30:12+05:30', 'source': './temp_paper-image-captioning.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='Nepali Image Captioning: Generating Coherent Paragraph-Length Descriptions Using Transformer \\nISSN: 2582-2640  72 \\n \\n \\nThe key contributions of this research work are: \\n1. We compiled the Nepali Paragraph dataset for image captioning by manually refining \\ncaptions from the English Stanford dataset [1] and creating 800 original Nepali cultural \\nimage descriptions, while also verifying the accuracy of Google -translated content \\nthrough human correction. \\n2. Utilize a Transformer -CNN architecture to generate Nepali Paragraph caption s from \\nimages. Through our research, we aim to contribute to the advancement of image \\ncaptioning technology in Nepali, paving the way for improved accessibility, tourism \\nexperiences, and urban development initiatives in Nepal and beyond. \\n Related Works \\nUtilizing computer vision algorithms for image captioning has primarily been focused \\non English language datasets largely due to the inherent complexities of other languages. \\nHowever, the increasing need for multilingual image captioning has prompted researche rs to \\nexplore the extension of these techniques to languages beyond English. This expansion not \\nonly facilitates image-text retrieval but also enables image captioning and translation in diverse \\nlinguistic contexts. \\nAmong the foundational techniques used i n image captioning is the Long Short -Term \\nMemory (LSTM) neural network [8], renowned for its ability to maintain long -short term \\nmemory, thereby addressing the short -term memory limitations of standard Recurrent Neural \\nNetworks (RNNs). This feature is part icularly crucial for various tasks such as Natural \\nLanguage Processing (NLP), object detection, and machine translation. The prevailing \\nsequence translation models typically employ advanced convolutional and recurrent neural \\nnetworks organized in an encode r-decoder setup, often drawing inspiration from machine \\ntranslation methodologies. \\nIn the domain of non-English language image captioning, significant strides have been \\nmade, particularly in languages such as Hindi and Bengali, which share similarities wit h \\nNepali. In Bengali language research, notable studies by S. Paul et al. [9] have explored \\ntechniques utilizing convolutional neural networks (CNNs) and recurrent neural networks \\n(RNNs) to generate Bengali captions from images. Subsequent investigations b y the same'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2024-04-30T10:30:12+05:30', 'author': 'Microsoft account', 'moddate': '2024-04-30T10:30:12+05:30', 'source': './temp_paper-image-captioning.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='Nabaraj Subedi, Nirajan Paudel, Manish Chhetri, Sudarshan Acharya, Nabin Lamichhane  \\n \\nJournal of Soft Computing Paradigm, Month 2024, Volume 6, Issue 1  79 \\n \\n \\nTable 1. Model Parameters for Transformer \\n \\n  \\n \\n \\n \\n \\n \\n \\n                                            \\n                                          \\n \\n \\n \\nTransformer utilizes essential parameters such as vocabulary size, learning rate, batch \\nsize, dropout rate, and optimizer choice (Adam), along with training epochs as mentioned in \\nTable 1. Additionally, it specifies Transformer-specific parameters like the number of attention \\nheads, row and column size, and maximum positi on encoding. With a vocabulary size of \\n27,000, a learning rate of 0.01, and a batch size of 64, the model trains over 15 epochs with a \\ndropout rate of 0.1 to prevent overfitting. It employs 8 attention heads and operates with a row \\nand column size of 8, wh ile the maximum position encoding is set to 25,001 for positional \\ninformation handling in input sequences. \\n Result and Discussion \\nBLEU scores [17] (BLEU-1, BLEU-2, BLEU-3, and BLEU-4) are calculated using the \\nNLTK bleu library. \\n Table 2 presents the obtained results of our work.  \\nParameter     Value \\nVocab Size 27000 \\nLearning Rate 0.01 \\nBatch Size 32 \\nDropout Rate 0.2 \\nOptimizer Adam \\nEpochs 15 \\nNumber of Head 8 \\nRow size 8 \\nColumn size 8 \\nmax position \\nencoding \\n25001')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retreiver.invoke(\"abstract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retreiver,\n",
    "        \"chat_history\": lambda x: memory.load_memory_variables({})[\"chat_history\"],\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"who are the authors of this academic paper?\"\n",
    "response=chain.invoke({\"question\":question})\n",
    "memory.save_context({\"question\": question}, {\"answer\": response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The authors of this academic paper are:\n",
      "\n",
      "1. Nabaraj Subedi\n",
      "2. Nirajan Paudel\n",
      "3. Manish Chhetri\n",
      "4. Sudarshan Acharya\n",
      "5. Nabin Lamichhane\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your previous question was \"who are the authors of this academic paper?\"\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"question\": \"what was my previous question?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for streaming responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The authors of this academic paper are:\n",
      "\n",
      "1. Nabaraj Subedi\n",
      "2. Nirajan Paudel\n",
      "3. Manish Chhetri\n",
      "4. Sudarshan Acharya\n",
      "5. Nabin Lamichhane"
     ]
    }
   ],
   "source": [
    "# to stream the answers \n",
    "\n",
    "for s in chain.stream({\"question\":\"who are the authors of this academic paper?\"}):\n",
    "    print(s, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_crew",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
