{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qU \"langchain[mistralai]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"MISTRAL_API_KEY\"):\n",
    "  os.environ[\"MISTRAL_API_KEY\"] = getpass.getpass(\"Enter API key for Mistral AI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"mistral-large-latest\", model_provider=\"mistralai\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qU langchain-mistralai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Access the HF_TOKEN\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/nirajanpaudel17/anaconda3/envs/learn_crew/lib/python3.10/site-packages (4.47.1)\n",
      "Requirement already satisfied: huggingface_hub in /Users/nirajanpaudel17/anaconda3/envs/learn_crew/lib/python3.10/site-packages (0.26.3)\n",
      "Requirement already satisfied: filelock in /Users/nirajanpaudel17/anaconda3/envs/learn_crew/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/nirajanpaudel17/anaconda3/envs/learn_crew/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/nirajanpaudel17/anaconda3/envs/learn_crew/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nirajanpaudel17/anaconda3/envs/learn_crew/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/nirajanpaudel17/anaconda3/envs/learn_crew/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/nirajanpaudel17/anaconda3/envs/learn_crew/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/nirajanpaudel17/anaconda3/envs/learn_crew/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/nirajanpaudel17/anaconda3/envs/learn_crew/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/nirajanpaudel17/anaconda3/envs/learn_crew/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/nirajanpaudel17/anaconda3/envs/learn_crew/lib/python3.10/site-packages (from huggingface_hub) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/nirajanpaudel17/anaconda3/envs/learn_crew/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/nirajanpaudel17/anaconda3/envs/learn_crew/lib/python3.10/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nirajanpaudel17/anaconda3/envs/learn_crew/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nirajanpaudel17/anaconda3/envs/learn_crew/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nirajanpaudel17/anaconda3/envs/learn_crew/lib/python3.10/site-packages (from requests->transformers) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = hf_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nirajanpaudel17/anaconda3/envs/learn_crew/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(hf_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nirajanpaudel17/anaconda3/envs/learn_crew/lib/python3.10/site-packages/langchain_mistralai/embeddings.py:181: UserWarning: Could not download mistral tokenizer from Huggingface for calculating batch sizes. Set a Huggingface token via the HF_TOKEN environment variable to download the real tokenizer. Falling back to a dummy tokenizer that uses `len()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"MISTRALAI_API_KEY\"):\n",
    "  os.environ[\"MISTRALAI_API_KEY\"] = getpass.getpass(\"Enter API key for MistralAI: \")\n",
    "\n",
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "\n",
    "embeddings = MistralAIEmbeddings(model=\"mistral-embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qU langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: capture\n"
     ]
    }
   ],
   "source": [
    "! capture --no-stderr\n",
    "! pip install --upgrade --quiet langgraph langchain-community beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "if not os.environ.get(\"LANGSMITH_API_KEY\"):\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "loader = TextLoader(\"./sample.txt\")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Step 2: Execute the retrieval.\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "\n",
    "# Step 3: Generate a response using the retrieved content.\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic in /Users/nirajanpaudel17/anaconda3/envs/learn_crew/lib/python3.10/site-packages (2.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/nirajanpaudel17/anaconda3/envs/learn_crew/lib/python3.10/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/nirajanpaudel17/anaconda3/envs/learn_crew/lib/python3.10/site-packages (from pydantic) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/nirajanpaudel17/anaconda3/envs/learn_crew/lib/python3.10/site-packages (from pydantic) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Hello', additional_kwargs={}, response_metadata={}, id='0ad46754-da8f-4685-8547-fc7ac0c4e809')]}\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello\n",
      "{'messages': [HumanMessage(content='Hello', additional_kwargs={}, response_metadata={}, id='0ad46754-da8f-4685-8547-fc7ac0c4e809'), AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 65, 'total_tokens': 74, 'completion_tokens': 9}, 'model': 'mistral-large-latest', 'finish_reason': 'stop'}, id='run-2ce269f2-ce77-494d-9b87-115a0bdf867b-0', usage_metadata={'input_tokens': 65, 'output_tokens': 9, 'total_tokens': 74})]}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "input_message = \"Hello\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    # print(step) \n",
    "    step[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "# Specify an ID for the thread\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is venv?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "`venv` is a module in Python that provides support for creating lightweight \"virtual environments\" with their own site directories, optionally isolated from system site directories. Each virtual environment has its own Python binary (which matches the version of the binary that was used to create this environment) and can have its own independent set of installed Python packages.\n",
      "\n",
      "### Key Features of `venv`:\n",
      "1. **Isolation**: It allows you to isolate your project dependencies from other projects. This means you can work on multiple projects with different dependencies without them interfering with each other.\n",
      "2. **Reproducibility**: You can easily recreate the same environment on another machine by sharing the requirements file (`requirements.txt`).\n",
      "3. **Dependency Management**: You can manage and install packages using `pip` within the virtual environment without affecting the global Python installation.\n",
      "\n",
      "### Basic Usage:\n",
      "1. **Creating a Virtual Environment**:\n",
      "   ```sh\n",
      "   python -m venv myenv\n",
      "   ```\n",
      "   This command creates a directory named `myenv` that contains the virtual environment.\n",
      "\n",
      "2. **Activating the Virtual Environment**:\n",
      "   - On Windows:\n",
      "     ```sh\n",
      "     myenv\\Scripts\\activate\n",
      "     ```\n",
      "   - On Unix or MacOS:\n",
      "     ```sh\n",
      "     source myenv/bin/activate\n",
      "     ```\n",
      "\n",
      "3. **Deactivating the Virtual Environment**:\n",
      "   ```sh\n",
      "   deactivate\n",
      "   ```\n",
      "\n",
      "4. **Installing Packages**:\n",
      "   ```sh\n",
      "   pip install package_name\n",
      "   ```\n",
      "\n",
      "### Example Workflow:\n",
      "1. Create a virtual environment:\n",
      "   ```sh\n",
      "   python -m venv myprojectenv\n",
      "   ```\n",
      "2. Activate the virtual environment:\n",
      "   ```sh\n",
      "   source myprojectenv/bin/activate  # On Unix or MacOS\n",
      "   myprojectenv\\Scripts\\activate  # On Windows\n",
      "   ```\n",
      "3. Install required packages:\n",
      "   ```sh\n",
      "   pip install requests\n",
      "   ```\n",
      "4. Work on your project.\n",
      "5. Deactivate the virtual environment when done:\n",
      "   ```sh\n",
      "   deactivate\n",
      "   ```\n",
      "\n",
      "### Benefits:\n",
      "- **Avoids Dependency Conflicts**: Different projects can have different dependencies without interfering with each other.\n",
      "- **Easy to Share**: You can share the environment setup with others by providing a `requirements.txt` file.\n",
      "- **Cleaner Development**: Keeps your global Python environment clean and uncluttered.\n",
      "\n",
      "Overall, `venv` is a powerful tool for managing project-specific dependencies and ensuring a clean and isolated development environment.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"What is venv?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "can you clarify step 2?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Certainly! Step 2 involves activating the virtual environment you created in Step 1. Activating a virtual environment means configuring your shell to use the Python interpreter and packages from the virtual environment instead of the global Python installation.\n",
      "\n",
      "Here's a detailed explanation of how to activate a virtual environment:\n",
      "\n",
      "### Activating a Virtual Environment\n",
      "\n",
      "1. **On Windows**:\n",
      "   - Open your command prompt or PowerShell.\n",
      "   - Navigate to the directory where your virtual environment is located.\n",
      "   - Run the following command to activate the virtual environment:\n",
      "     ```sh\n",
      "     myenv\\Scripts\\activate\n",
      "     ```\n",
      "   - After activation, your command prompt will change to show the name of the activated environment, like this:\n",
      "     ```\n",
      "     (myenv) C:\\path\\to\\your\\project>\n",
      "     ```\n",
      "\n",
      "2. **On Unix or MacOS**:\n",
      "   - Open your terminal.\n",
      "   - Navigate to the directory where your virtual environment is located.\n",
      "   - Run the following command to activate the virtual environment:\n",
      "     ```sh\n",
      "     source myenv/bin/activate\n",
      "     ```\n",
      "   - After activation, your terminal prompt will change to show the name of the activated environment, like this:\n",
      "     ```\n",
      "     (myenv) user@hostname:~/path/to/your/project$\n",
      "     ```\n",
      "\n",
      "### What Happens During Activation?\n",
      "- The `activate` script modifies the `PATH` environment variable to prioritize the Python interpreter and scripts from the virtual environment.\n",
      "- It also sets the `VIRTUAL_ENV` environment variable to the path of the virtual environment directory.\n",
      "- Your shell prompt is updated to include the name of the virtual environment, indicating that it is active.\n",
      "\n",
      "### Deactivating the Virtual Environment\n",
      "When you are done working in the virtual environment, you can deactivate it by simply running:\n",
      "```sh\n",
      "deactivate\n",
      "```\n",
      "This command will revert your shell back to using the global Python installation.\n",
      "\n",
      "### Example Workflow:\n",
      "1. **Create a Virtual Environment**:\n",
      "   ```sh\n",
      "   python -m venv myprojectenv\n",
      "   ```\n",
      "2. **Activate the Virtual Environment**:\n",
      "   - On Windows:\n",
      "     ```sh\n",
      "     myprojectenv\\Scripts\\activate\n",
      "     ```\n",
      "   - On Unix or MacOS:\n",
      "     ```sh\n",
      "     source myprojectenv/bin/activate\n",
      "     ```\n",
      "3. **Install Required Packages**:\n",
      "   ```sh\n",
      "   pip install requests\n",
      "   ```\n",
      "4. **Work on Your Project**.\n",
      "5. **Deactivate the Virtual Environment When Done**:\n",
      "   ```sh\n",
      "   deactivate\n",
      "   ```\n",
      "\n",
      "By following these steps, you ensure that your project's dependencies are isolated and managed within the virtual environment, avoiding conflicts with other projects or the global Python installation.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"can you clarify step 2?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "can you tell me more about steps on Unix or macos?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (bq8PzpkXz)\n",
      " Call ID: bq8PzpkXz\n",
      "  Args:\n",
      "    query: steps to activate virtual environment in Unix or MacOS\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': './sample.txt'}\n",
      "Content: A virtual environment may be “activated” using a script in its binary directory (bin on POSIX; Scripts on Windows). This will prepend that directory to your PATH, so that running python will invoke the environment’s Python interpreter and you can run installed scripts without having to use their full path. The invocation of the activation script is platform-specific (<venv> must be replaced by the path to the directory containing the virtual environment):\n",
      "\n",
      "Platform\n",
      "\n",
      "Shell\n",
      "\n",
      "Command to activate virtual environment\n",
      "\n",
      "POSIX\n",
      "\n",
      "bash/zsh\n",
      "\n",
      "$ source <venv>/bin/activate\n",
      "\n",
      "fish\n",
      "\n",
      "$ source <venv>/bin/activate.fish\n",
      "\n",
      "csh/tcsh\n",
      "\n",
      "$ source <venv>/bin/activate.csh\n",
      "\n",
      "pwsh\n",
      "\n",
      "$ <venv>/bin/Activate.ps1\n",
      "\n",
      "Windows\n",
      "\n",
      "cmd.exe\n",
      "\n",
      "C:\\> <venv>\\Scripts\\activate.bat\n",
      "\n",
      "PowerShell\n",
      "\n",
      "PS C:\\> <venv>\\Scripts\\Activate.ps1\n",
      "\n",
      "Added in version 3.4: fish and csh activation scripts.\n",
      "\n",
      "Added in version 3.8: PowerShell activation scripts installed under POSIX for PowerShell Core support.\n",
      "\n",
      "Source: {'source': './sample.txt'}\n",
      "Content: In order to achieve this, scripts installed into virtual environments have a “shebang” line which points to the environment’s Python interpreter, #!/<path-to-venv>/bin/python. This means that the script will run with that interpreter regardless of the value of PATH. On Windows, “shebang” line processing is supported if you have the Python Launcher for Windows installed. Thus, double-clicking an installed script in a Windows Explorer window should run it with the correct interpreter without the environment needing to be activated or on the PATH.\n",
      "\n",
      "When a virtual environment has been activated, the VIRTUAL_ENV environment variable is set to the path of the environment. Since explicitly activating a virtual environment is not required to use it, VIRTUAL_ENV cannot be relied upon to determine whether a virtual environment is being used.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "To activate a virtual environment on Unix or macOS, you use the `source` command followed by the path to the `activate` script within the virtual environment's `bin` directory. This modifies your shell environment to use the Python interpreter and packages from the virtual environment. Here are the specific steps:\n",
      "\n",
      "1. **Open your terminal**.\n",
      "2. **Navigate to your project directory** where the virtual environment is located, for example:\n",
      "   ```sh\n",
      "   cd path/to/your/project\n",
      "   ```\n",
      "3. **Activate the virtual environment** by running:\n",
      "   ```sh\n",
      "   source myenv/bin/activate\n",
      "   ```\n",
      "   Replace `myenv` with the name of your virtual environment directory. After activation, your terminal prompt will change to show the name of the activated environment, like this:\n",
      "   ```\n",
      "   (myenv) user@hostname:~/path/to/your/project$\n",
      "   ```\n",
      "\n",
      "This indicates that the virtual environment is active and you can now install and use packages within this isolated environment.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"can you tell me more about steps on Unix or macos?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_message = \"what is the pdf about?\"\n",
    "\n",
    "# for step in graph.stream(\n",
    "#     {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "#     stream_mode=\"values\",\n",
    "#     config=config,\n",
    "# ):\n",
    "#     step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_crew",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
